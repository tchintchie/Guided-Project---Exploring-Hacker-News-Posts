{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts/download), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post\n",
    "- `title`: The title of the post\n",
    "- `url`: The URL that the posts links to, if it the post has a URL\n",
    "- `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: The number of comments that were made on the post\n",
    "- `author`: The username of the person who submitted the post\n",
    "- `created_at`: The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Removing Headers from a List of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']]\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "file = open(\"hacker_news.csv\")\n",
    "readit = reader(file)\n",
    "listit = list(readit)\n",
    "hn = listit[1:]\n",
    "header = listit[0]\n",
    "\n",
    "print(hn[:3])\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculating the Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Ask Comments: \n",
      "94986\n",
      "Average Comments for each Ask Post: \n",
      "10\n",
      "Sum of Show Comments: \n",
      "49633\n",
      "Average Comments for each Show Post: \n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def total_comments(dataset, comm_ind):\n",
    "    sum_comments = 0\n",
    "    for row in dataset:\n",
    "        comm = int(row[comm_ind])\n",
    "        sum_comments += comm\n",
    "    return sum_comments\n",
    "\n",
    "\n",
    "total_ask_comments = total_comments(ask_posts, 4)\n",
    "total_show_comments = total_comments(show_posts, 4)\n",
    "\n",
    "print(\"Sum of Ask Comments: \")\n",
    "print(total_ask_comments)\n",
    "print(\"Average Comments for each Ask Post: \")\n",
    "avg_ask_comments = round(total_ask_comments/len(ask_posts))\n",
    "print(avg_ask_comments)\n",
    "\n",
    "print(\"Sum of Show Comments: \")\n",
    "print(total_show_comments)\n",
    "print(\"Average Comments for each Show Post: \")\n",
    "avg_show_comments = round(total_show_comments/len(show_posts))\n",
    "print(avg_show_comments)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Finding the Amount of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9/26/2016 2:53', 7], ['9/26/2016 1:17', 3], ['9/25/2016 22:57', 0]]\n"
     ]
    }
   ],
   "source": [
    "def posts_per_hour(dataset, time, comms):\n",
    "    result_list = []\n",
    "    for row in dataset:\n",
    "        create = row[time]\n",
    "        comm = int(row[comms])\n",
    "        result_list.append([create,comm])\n",
    "    return result_list\n",
    "\n",
    "pph = posts_per_hour(ask_posts,6,4 )\n",
    "print(pph[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n",
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in pph:\n",
    "    date = row[0]\n",
    "    comm = row[1]\n",
    "    datum = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = datum.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comm\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comm\n",
    "    \n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11], ['01', 7], ['22', 9], ['21', 9], ['19', 7], ['17', 9], ['15', 29], ['14', 10], ['13', 16], ['11', 9], ['10', 11], ['09', 7], ['07', 7], ['03', 8], ['23', 7], ['20', 9], ['16', 8], ['08', 9], ['00', 8], ['18', 8], ['12', 12], ['04', 10], ['06', 7], ['05', 9]]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for key in counts_by_hour:\n",
    "    avg_by_hour.append([key, round(comments_by_hour[key]/counts_by_hour[key])])\n",
    "\n",
    "print(avg_by_hour)\n",
    "print(len(comments_by_hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Sorting and Printing Values from a List of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, '02'], [7, '01'], [9, '22'], [9, '21'], [7, '19'], [9, '17'], [29, '15'], [10, '14'], [16, '13'], [9, '11'], [11, '10'], [7, '09'], [7, '07'], [8, '03'], [7, '23'], [9, '20'], [8, '16'], [9, '08'], [8, '00'], [8, '18'], [12, '12'], [10, '04'], [7, '06'], [9, '05']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    first = row[1]\n",
    "    second = row[0]\n",
    "    swap_avg_by_hour.append([first,second])\n",
    "\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 29 average comments per post\n",
      "13:00: 16 average comments per post\n",
      "12:00: 12 average comments per post\n",
      "10:00: 11 average comments per post\n",
      "02:00: 11 average comments per post\n",
      "14:00: 10 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "top5 = sorted_swap[:6]\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "def print_avg(dataset, av, hr, txt):\n",
    "    for row in dataset:\n",
    "        avg = row[av]\n",
    "        hour = row[hr]\n",
    "        formatted = dt.datetime.strptime(hour, \"%H\")\n",
    "        only_hour = dt.datetime.strftime(formatted, \"%H:%M\")\n",
    "        template = str.format(\"{time}: {comms} average \"+ txt + \" per post\", time = only_hour, comms = avg)\n",
    "        print(template)\n",
    "\n",
    "print_avg(top5, 0,1, \"comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Next Steps\n",
    "\n",
    "- Determine if show or ask posts receive more points on average.\n",
    "- Determine if posts created at a certain time are more likely to receive more points.\n",
    "- Compare your results to the average number of comments and points other posts receive.\n",
    "- Use Dataquest's data science project style guide to format your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Points for Ask Posts:\n",
      "103378\n",
      "Average Points for Ask Posts:\n",
      "11\n",
      "Total Points for Show Posts:\n",
      "150781\n",
      "Average Points for Show Posts:\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "total_points_ask = total_comments(ask_posts, 3)\n",
    "total_points_show = total_comments(show_posts, 3)\n",
    "print(\"Total Points for Ask Posts:\")\n",
    "print(total_points_ask)\n",
    "print(\"Average Points for Ask Posts:\")\n",
    "avg_points_ask = total_points_ask/len(ask_posts)\n",
    "print(round(avg_points_ask))\n",
    "print(\"Total Points for Show Posts:\")\n",
    "print(total_points_show)\n",
    "print(\"Average Points for Show Posts:\")\n",
    "avg_points_show = total_points_show/len(show_posts)\n",
    "print(round(avg_points_show))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9/26/2016 0:36', 2], ['9/26/2016 0:01', 1], ['9/25/2016 23:44', 1], ['9/25/2016 23:17', 2], ['9/25/2016 20:06', 1], ['9/25/2016 19:06', 1]]\n"
     ]
    }
   ],
   "source": [
    "show_per_hour = posts_per_hour(show_posts, 6,3)\n",
    "print(show_per_hour[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n",
      "{'00': 4291, '23': 5060, '20': 6948, '19': 8928, '18': 9935, '16': 11487, '14': 10503, '10': 4303, '09': 3762, '08': 4640, '06': 3071, '03': 2168, '21': 5990, '17': 10563, '15': 11657, '11': 7742, '07': 3303, '04': 2707, '13': 10381, '12': 10787, '01': 2931, '22': 5026, '02': 2764, '05': 1834}\n"
     ]
    }
   ],
   "source": [
    "points_by_hour = {}\n",
    "\n",
    "for row in show_per_hour:\n",
    "    date = row[0]\n",
    "    point = row[1]\n",
    "    datum = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = datum.strftime(\"%H\")\n",
    "    if hour not in points_by_hour:\n",
    "        points_by_hour[hour] = point\n",
    "    else:\n",
    "        points_by_hour[hour] += point\n",
    "    \n",
    "print(counts_by_hour)\n",
    "print(points_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['00', 179], ['23', 211], ['20', 290], ['19', 372], ['18', 414], ['16', 479], ['14', 438], ['10', 179], ['09', 157], ['08', 193], ['06', 128], ['03', 90], ['21', 250], ['17', 440], ['15', 486], ['11', 323], ['07', 138], ['04', 113], ['13', 433], ['12', 449], ['01', 122], ['22', 209], ['02', 115], ['05', 76]]\n"
     ]
    }
   ],
   "source": [
    "avg_points_by_hour = []\n",
    "\n",
    "for key in points_by_hour:\n",
    "    avg_points_by_hour.append([key, round(points_by_hour[key]/len(points_by_hour))])\n",
    "\n",
    "print(avg_points_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[179, '00'], [211, '23'], [290, '20'], [372, '19'], [414, '18'], [479, '16'], [438, '14'], [179, '10'], [157, '09'], [193, '08'], [128, '06'], [90, '03'], [250, '21'], [440, '17'], [486, '15'], [323, '11'], [138, '07'], [113, '04'], [433, '13'], [449, '12'], [122, '01'], [209, '22'], [115, '02'], [76, '05']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_points_by_hour = []\n",
    "\n",
    "for row in avg_points_by_hour:\n",
    "    first = row[1]\n",
    "    second = row[0]\n",
    "    swap_avg_points_by_hour.append([first,second])\n",
    "\n",
    "print(swap_avg_points_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Show Posts Highest Scores:\n",
      "15:00: 486 average points per post\n",
      "16:00: 479 average points per post\n",
      "12:00: 449 average points per post\n",
      "17:00: 440 average points per post\n",
      "14:00: 438 average points per post\n",
      "13:00: 433 average points per post\n"
     ]
    }
   ],
   "source": [
    "sorted_points = sorted(swap_avg_points_by_hour, reverse=True)\n",
    "top5_points = sorted_points[:6]\n",
    "print(\"Top 5 Hours for Show Posts Highest Scores:\")\n",
    "print_avg(top5_points, 0,1, \"points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
